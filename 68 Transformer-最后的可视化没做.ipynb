{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007a3dfb-6452-4bc0-a837-4cfe054c4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ae078-6c9a-41e0-a3f3-f0ec6e5e1631",
   "metadata": {},
   "source": [
    "基于位置的前馈网络（Position-wise Feed-Forward Network, FFN）是Transformer模型中的一个关键组件。它对序列中的每个位置独立地应用相同的前馈神经网络，从而实现对每个位置的特征进行变换。这种处理方式使得前馈网络能够对每个位置进行独立变换，而不依赖于其他位置的特征。这与卷积神经网络（CNN）和循环神经网络（RNN）有所不同，后者通常会考虑输入数据的局部或全局信息。\n",
    "\n",
    "### 基于位置的前馈网络（FFN）结构\n",
    "\n",
    "基于位置的前馈网络通常由两层全连接层（或线性层）组成，中间使用激活函数进行非线性变换。在Transformer中，每个位置的特征向量都通过相同的前馈网络进行变换。\n",
    "\n",
    "具体来说，FFN的步骤如下：\n",
    "\n",
    "1. **输入线性变换**：首先对输入进行线性变换，将输入特征维度从`ffn_num_input`变换为隐藏层维度`ffn_num_hiddens`。\n",
    "2. **激活函数**：然后通过ReLU激活函数引入非线性。\n",
    "3. **输出线性变换**：最后再进行一次线性变换，将隐藏层的输出变换为最终的输出特征维度`ffn_num_outputs`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f8769-6611-4aa1-9b05-9a255ae4835d",
   "metadata": {},
   "source": [
    "基于位置的前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c2fd83-8ad2-4477-a79a-d96bd8014c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    '''\n",
    "    基于位置的前馈网络\n",
    "    初始化方法接收输入特征维度`ffn_num_input`，\n",
    "    隐藏层特征维度`ffn_num_hiddens`和输出特征维度`ffn_num_outputs`。\n",
    "    '''\n",
    "    def __init__(\n",
    "        self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs\n",
    "    ):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        '''\n",
    "        第一层线性变换，将输入特征维度变换为隐藏层特征维度。\n",
    "        '''\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        '''\n",
    "        使用ReLU激活函数引入非线性。\n",
    "        '''\n",
    "        self.relu = nn.ReLU()\n",
    "        '''\n",
    "        第二层线性变换，将隐藏层特征维度变换为输出特征维度。\n",
    "        '''\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        在前向传播中，首先通过第一层线性变换，\n",
    "        然后通过ReLU激活函数，最后通过第二层线性变换。\n",
    "        '''\n",
    "        return self.dense2(\n",
    "            self.relu(\n",
    "                self.dense1(X)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fdde5a-b5a8-4187-bb01-d394007a2681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5234, -0.1565,  0.6883, -0.3492, -0.3914, -0.6978, -0.6405,  0.0026],\n",
       "        [ 0.5234, -0.1565,  0.6883, -0.3492, -0.3914, -0.6978, -0.6405,  0.0026],\n",
       "        [ 0.5234, -0.1565,  0.6883, -0.3492, -0.3914, -0.6978, -0.6405,  0.0026]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "创建了一个基于位置的前馈网络`ffn`，输入的张量形状为`(2, 3, 4)`，\n",
    "表示批量大小为2，序列长度为3，特征维度为4。\n",
    "前馈网络会将输入变换为形状为`(2, 3, 8)`的输出。\n",
    "'''\n",
    "ffn = PositionWiseFFN(4, 4, 8)\n",
    "ffn.eval()\n",
    "ffn(\n",
    "    torch.ones(\n",
    "        (2, 3, 4)\n",
    "    )\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c5175d-09df-4f68-8242-97f3673b7b63",
   "metadata": {},
   "source": [
    "\n",
    "通过这种方式，基于位置的前馈网络可以在保持每个位置的独立性的同时对特征进行非线性变换，使得模型能够更好地捕捉复杂的特征关系。\n"
   ]
  },
  {
   "attachments": {
    "69e88468-a456-455b-a19b-f43a68cb9dcc.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAABnCAIAAACctV1cAAAgAElEQVR4Ae2dv4sbSfr/P/9A/xEHHR2GCc6wcJ7IE67wgQcuWMHADjgwYgOjDRbhYBE+EI05BrEcFt/AiA320HAGGc6HHBgNHHunCYzmwMcYbkCGCRQ4UGBQ4KC/PFVdVU/9aKn1a8ay32IYVVdXPfXUq56qerq6uvV/KT4gAAIgAAIgAAIgoAj8nwrgGwRAAARAAARAAARSeAYwAhAAARAAARAAAUMAnoFhgRAIgAAIgAAIgAA8A9gACIAACIAACICAIQDPwLBACARAAARAAARAAJ4BbAAEQAAEQAAEQMAQgGdgWCAEAiAAAiAAAiAAzwA2AAIgAAIgAAIgYAjAMzAsEAIBEAABEAABEIBnABsAARAAARAAARAwBOAZGBYIgQAIgAAIgAAIwDOADYAACIAACIAACBgC8AwMC4RAAARAAARAAATgGcAGQAAEQAAEQAAEDIFr9gwGjShqDNJ03Dkody6NWoHQZaccJYPACUSBAAiAAAiAAAisjcA6PIPTJIrUvE7hBeZv7RmMj5MoipLTrGLj43JU8EOORSp8iwIZDjrjtaGDIBAAARAAARD4DAms7hkMyC841hPuuHPAD+cgIw8gm9rT9DQxYT8f1gx8JogBARAAARAAgXUTWNUzoIt+Z5GALyFIdSmm+CdnyQGewbrbHvJAAARAAARAwCewkmcg1vzVfQQmW8TnTPAsGd0DOC5H4RV+Wooo8ClUil0mOxIui76FwU4gCAIgAAIgAAJfKIHlPQMx/ZudAQ6/wFqCk0IeniY5noGXesaawWJrEkxneAYeZkSAAAiAAAh84QSW9AzExD9nP4FIk60oyPTuGsBBZ0xzc7Hr/hmeQU4bUqF6E0NOGkSDAAiAAAiAAAhwAkt6BmX2HIEQR4v/gWV5mvit2w200sBna5rvrQRamutG5B5zx8J6+pF5BoOkoP/B2SAMAiAAAiAAAl8egSU9AweUWBJIOpf6CQXnvDl0PYN0kAQ8A5M+C4mlhaQRcj5YWmfXgvEMLscdrB8wUAiCAAiAAAiAQB6BdXgG1t1666rdL9XzDOY/5UhZpPdg31CgiZ/vXvSWH4xnQHo4T1f6qiEGBEAABEAABEAgXd0zcGdcMZHzFX6LsucZpPb8bSXW7y8y9ylox2JZvgWJXqJwOVbLFAEPw5Xs3dpwCsMhCIAACIAACIDAqp6BO/sSUZqkrc0EDHPmGYhlhki+IkncKVCvPTY3F4SHEUUHSXJg3USgeL5UIIQHI33dKIbntVY7mJYIggAIgAAIgMCXSmAlz8CdaDVEWtj3nlwQkdk+Qr4JkXsS8n6BTJlN4eRnZGsG+qJfJjBCjD+hVchxUOyU8AwYLwRBAARAAARAIE1XuJtAbsGcj3rowJrpQ9jFDB01BiFXQ3gGDfHeI+MKCCEyl7uBkb8iSSkQKhNxIAACIAACIAACPoGV1gx8cTxmfFxmv6fAz4TC2TSvlgd0End5QJ9AAARAAARAAARAYP0ENugZrF9ZSAQBEAABEAABENgwAXgGGwYM8SAAAiAAAiCwVQTgGWxVc0FZEAABEAABENgwAXgGGwYM8SAAAiAAAiCwVQTgGWxVc0FZEAABEAABENgwAXgGGwYM8SAAAiAAAiCwVQTgGWxVc0FZEAABEAABENgwAXgGGwa8/eLHJ63mUVP+9S7SdDrsqMPum+n21w81AAEQAAEQsAjAM7Bw4CBIYPqmtR9FtZeZHzB6Wq48GYw+BNMiEgRAAARAYLsJwDPY7va7Ku0n3ftR/GN/mqbT06R2PLqqclEOCIAACIDAVROAZ3DVxLe0vMmLahRVuq+7zZ/Pl7iFMMUCw5Y2PNQGARD48gjAM7iKNp9OlphMtWLTyacwrU779TiKvu8tU5PTJL7XHYsKTV5Wbx4Ndd0QAAEQAAEQ+NQIwDPYdItMhz9VktNl5lOl2XTw+HA1CUrSKt8fBsntOLrbXuJGwvCn3dJTmW/afxjVXq1CY5U6rCnvx8n5ab9/ej75uCaBEAMCIAACnxKBJT2D1p29G+YnmG/s3Sm1Xl9ntYZPSqXbmUZ7P7FL0nGvsqMVjW/yU1ei7/jZYSlQ6KT30AK4//Sc1Dlr3mTK1l5OlI6j9jeHnXfq6Oq/P446R93RRXs/2m2eOcWPez9WKt8F/pJXUv9x5yBOMvMYNm9t909jT163qt+3uif9/svW4VeV7jU2itMOOAQBEACBNRFY0jMQpQ/qNI0lgzWpsrqYQSOO4yiK9pLX1lXp5KS++31PT7OrF1RUwvtedadO2/bCn1H7bhRFN9WsSYkmL6o37reH770MZ83dg45ckPfObTpi1PkhGdAdDbMPcYEiJ71qVMsgXLRLt5rDNJ3mMllA8DUkPWuWGwOt+6ARxY+ZG3oNCqFIEAABEFg/gZU8g+ST8wzKnVft/SiKbidDPX6naXrZKTeuwYEZHu3uzrynPnleiaLIpHnXqdzv5CzXj9p34/oJr9X6rSEkcdJ/nPSUp5LtQ1SHofRe3GkSK/dx9HQ/ejRIL9rtUy/ZlUeMn1W4T1ag/GHzvnUzZfAoiq7DrgqoiiQgAAIgsDyBlT2Da7uQDdR50KCVapp+omiPXdtdk2cwSGJ/7d1WW27ri8W6wrtO5aA5zN9sOHpaih7mL0DYgtdwNB12HlX3v4qjeL8p12Au+8m3N+MounFQaz4r+oTC8KfdOC7Vj/u9X5LmUX3vu1bnSTfH+1mD1sVFjI/LySIOyvSkbntmw+atuPriGpaiitcRKUEABEBgCQIb9gym4+FJr/Ok3T0Zjvnl7sfpxHzECRPD0o2HveNW+3l/qJfRP0wmk9HwpH/+Pp1eDp1dYNIzSFO5Sr9ndu0F1wzenw9edtrHveElKzFHPqn7btg/Oad54AMp0D9TFdL70ZgYaomz5m5Un7tSMTzajaKo8nM3OZAr9vmN+DqJCwjMz38tZ7JNBtPJZCr3603Xeifh43R01u+fjqz5+eM0K2tmjRf0DKb9h+KeiLTcaTo6PrxxL2+BZ2bBOAkCIAACnzaBTXoG73vVONr/f0OazE+S/Z2SmaovevUH+3T5Gd/cb/RpWH/T3qetgjf2suX06fnPlZt/TPrvJuOzTvX2jcozus4cPauWxU7DaiOpPWnVfhfFD8wGAuUZpOm7TlncUxB3x/27CSR8735r8G4yGZ93fyyVHgkdcuWPulLbqN55Vqv93Ouf9Fr34vhe5/x1q/qw3Tvpdxv70U6le2lae3xcjoosqFy0S3RTpjx/g+Flp1wkmVHhEwjxTQbrVmf6tq23l8Zmkp72f6z385detBYLegbD5Pve5G1LNJbYJvq7xOw40EIRAAEQAIHtJ7BJz4C2spstWnRxHFvbFUWM2aA3elqu/5pdd09Pk91ov32RAab78XE1cwFogpQP1o+7D0rln8yOAuMZpOnoF0q1+0iM3vaaweRFNY5rbPKgNQbzREOOfCmw8lxdnf5K+y9jvbw/7deiqHysFzfSQSMqtvg/bP4uilhl841qkERR3gL49FW9dKc076/QlJmvwOJnXjdvbmjvJ+3uLNV+7g3fjc9P2tXbCv5FuxJ4GCSg+WKewUW7+gv5pmrJYNp/GO///CncFQlUDVEgAAIgsAqBTXgGZr2Y1pCVdnQNHdlPrInLZTXXjtr3aNe6+Ex6D6JIbGLPIsQaQDYpipmbz8FZmjTlnkGajjr34ijaJW/D8gyGzVtRxFYaUsoYRXr/fI58ob/yTtI0PaX9l/VfTeGJ7xnM35426f9Yrn4vnJiZexVFMeQZbP3LADSwQoFR97u9ve+ytyTxHMOjfbMElabp+171m/YonQ4atW54gyS/gTWZTCbnT8v1lxRgH22tqfMZP6s6j2uSPdyxNiQ6WXAIAiAAAltKYAOewevkUF86T867R9XynVL5Qb1+b9f1DOSGALnkftY8NFdgNAVGtw7r6jf9zA/9yQcN7DlYo7c9A7qncEg3LGr9t+zZhHH3MHK3lAvPQD1zP8szYGsewjNgV/CkM/dXSOYcz2A6aJSTXycp34eoKxMIUBGHz8yyRCDJClFiifza/oUVl42ll4tYIv+1koNH1d7bbo3vPGXp0zdd/YuRMlC/t7v/IPsNSXWqPVBLQjxrmk77D90tI7SGFCfKl7WT4wgEQAAEtpnA+j2DyYuqnC+nZ639ON7/aSgH28CaQZqKx/b22xfT/o9VdqknLuvzLsjEzM2mZIPf9QxS2iZGvsHd/ZKepOnOt7vOLzyDUnbzIke+0H+dnsHouFJRP02U7UPUtypMnXiIPINgxSmR2cI5mfHJvSjm5XxK4cnFwOw/nanY+Piw/E1V34GamZZOLnI3QWwysCSKZS175ck6jwMQAAEQ2FoCa/cMJt378uLbvSOgPINx70nPXPaKy+XdR/WqPciKmVK9HkfCfTfM3v+TM3OLmwL23QrKOO7SPQV++S6eXPiG7yqnV/aamxc58hf1DOghQ/VjAb55jI4rfIdEKvZkzHn3MG1lUAsbvsT35/2T/rw/+wkRX0h+zMuXLze6npBfcuEzv9bnALQlLeAZXLRLj+ynTMhI4i/szo6ND0cgAAKfL4GVPAPag8ev7D+O+4/342wzgfAMzJbDSe9BLO4mjNoPrXf5CSfAe4dP9lyDeGcw0WcbzsXMHVhU/zhqH5Rab7y2uuzSuoFeM0jT6etkj+/4+9CvxezB9Bz5YgciW1IO3U3YZXvf6KVAfKuE1uvjZHhc3XOdhlH7zrx9iLTZgm100AKvJLCzs/Pvf/87v6jJ4LjdftLuvbu+VYnTRO1ZyVeTnSnuGYyfVeLb9ew5F1qeGXXu3Sg9xqMJjCaCIAACnxGBJT2D1p3Snv49gp290p0SPYKYfdTs9a5X+zqmt+IcNevf13tvB82v4xu3S9XnZsmASJ41d4Mz6PtB8+CGzF67X2md0ZQzfKLLtX6sYfjE/AxB/JXeyZg1FD2MwDwDes3vm07t7n7lUbN5VCvfLjd/zW4v58gftr5W9dvZq70Y9n5Q9Y1vln7oDV/USl/J+sc3v25l957Jw1AopCKTXl39uAM9r/lYXYaOe9UsOz3ucPPrw/bbgIlNX9UKPQYZyLpqlFwwmCFl9HNduHvD5u2qfmHijPSbODV6Wil+K2GRuwn0JoPe227ljxWx8aV2+PVh88S24U3UBzJBAARA4JoILOkZFNdW7Ahn15H+z9NZew89wfTqIfOAg3d6pQhXt5WE+ZnptsX6Fpyn/R+v7TG5nZ2dX375xa+hjhm/TFr0nkR6li/8ymG/3XXm9QRG7Tu2HzZPbOE1A73JQNhLgTclzCsZ50EABEDgkyawcc8gXPsPw1a2DODsPQwn39LY6atafL8b3u2+aJU+9Gs7/B0Mi+ZfPv0///nPKIoK5f/Qr33tLtiIjIOOflylkKDFE112yvzGVgEB07Nen72ZKjeHepNBbgKcAAEQAIHPi8A1eQb05mDxAN7bVuWxeVXR58VW7n8sOc/BL1fH0dPyoXqQYTkJS+fa2dl58uRJgeyjbqOV87sPG/cMpq9qfJNHAW2LJvHfZFA0J9KBAAiAwHYSuCbPIJ0On1QPvzusHuU8QL6dNANafxjM/0GEQDY76qJdvn9Fv0L03//+l5c9HA7dBYOP4/7Rodp2QVtL4u96k3Q6fNYbfUzTcb8f2CQR9gwmvzYr31brR83Wyrftx8fum4h4LVYJj1709D7YVeQgLwiAAAhsC4Hr8gy2hc869HzfT35a4TcSp8P2o97VvIb3X//6161bt/72t7/pat+5c+fPf/6zPhRvlizVX4r9d29aJfXDEONn9PyH+ARv9gc8g/Ez/CIR44ogCIAACHwyBOAZfDJN8Qko8te//vUvf/nL73//e6nL//73P2fBYPKyan4qgh6+YK9+cvR/06l8V1F/5dKdQxWuVH7sjVN6mVX8lfihh29bn/H9JIcKDkEABEDg0ycAz+DTb6Mr1XAymfzmN7/5+9//nqZppVKxFwzoByaqL7ItlfQUpf1+qnxFvTUDeu2x/1qqfAE4AwIgAAIgcFUE4BlcFentKeeHH374wx/+kKbpb3/7W0fr4eNYvZ553DnYK7y50vMMaM2gwA9PO8XjEARAAARAYPME4BlsnvG2lfCf//wniqJ//OMff/rTn1zd33Ur37V6J732w2rrdfHnMX3PIJ2etQ5JVL/7pN4JbFp0S8YxCIAACIDA1RCAZ3A1nLeslG+//fabb77JUZr/tnZOEjc64BnIJP5PJrpZcQwCIAACIHC1BOAZXC3vL7a0jb8D8Ysli4qDAAiAwJoJwDNYM1CIAwEQAAEQAIGtJgDPYKubD8qDAAiAAAiAwJoJwDNYFej0/fng9HxTP/q0qnbIDwIgAAIgAAKLEYBnsBgvO/V0cFRtPu/3X7YqOzcqz67mRYW2CjgCARAAARAAgbUSgGewAs6Ldvkgkb/XR6/9iYIvBl5BPrKCAAiAAAiAwJUTgGewAvKLTjnea70REuhVwXHyegVpyPoJERgkUaTe6fQJqbU2VT5Ozk/7/dPzCZ4ZWRtTCAKBz4fASp7B+LgcNQZBGINGVD4Wv7sTPJ2mKU2l1/N+XFKbPussndYM4nrod5PGnQM1x5zSdBPmlUeJxQ8aUR5tlmpGcJD4VZ792weXnbL6zaQZcrNTodrN0NmzEAI102YYyaxIP8ZRkyZ4+uRYqZOaH5Lmc+se5jNXK17OiuFlKjh53ap+3+qe0F2ww68q3Xcr6lA8+7hzYDrdoKH6hRLgx6gzhb8XNEImd6756bR+P7rKFtdqbDBAxr/ISDWjm2daWu3i4CIbDnX8T5yzZczzGqO4dRlJhYYgk3zNoS/HM1BjaFRgxF8Y8qh9d69+EngnIHkhZoLJsw+K9z/ONavT/ZR/4+eTMWYITlPZx/yeJv2zPGdF9VjyHnI/Wklvpk9VuWGabnpr7AhlCbiSzhCT5eJktHohibPjQricHJfjjjuGCjNrDMaXM91iR86ChytV8KxZbgymqsRBI4ofD9VRyiWHmlwbVdhiQ1kozoz7VisTK91AcjbqGG6sw+bJpXjLel2joooVaEdKQ0pmrXaasD6r2BgfWgv0Ayrxur8Lt8s6CqY2oo9ptXlSnaHJT05ghVjR3Kbbynolp6npL0twnjlAybrQf3V5ICzNROeFMsu0hVtMqEa6R/iV5jFUZSuvPmnL191B4gq2QjH9Cyqm9XADS3oGwZksjNjMi3bZRGRV7W2JhY7IFplKwS5nmqeQyOng8WH9VcAtCKyLhI3JdBVVoB40zSmn+zkVURnltx6zxCGhTgZmiCSZ4Y8hI8Zl1Ze4cEcNOqWGEiNTZvTj2TjuDOI55m7GfapvYxAoy5RKIdZ2mqFmYidVPmJO0V5iESHkCzjh806s0Z8zXFO4aAVZccPm/TbfKDt4ZEbMNBWegbEBlo+CtlE5J/3D4Pya0o9ymSFSpwmvvvhC7RgyMEXYN7YCRphVWQsR4seXY2ESSrIuM9NWcmA0dC10ynUHFujsKxYtJipqoEXG58CYoNXw28XpIuZQAV+Us6dqNlZoHYTVac+ARWfBWfpngydZCq3+NjK3yWjNQ2bAZOZBhVBeY/ZcAy1fB7IFdZHeqxrPqsJmjlAxa/he0jOQJfsNoDWy+r+qKmeYE964r+D0Ma8Ki1Kenv/cbL8V12AX/b51oUgDt28NVKI9EmU2d6rhyVFYTnJGH8d8hZwcihTNSLqdk53i5qjLp0hrwtBnSDP/poY9Miqk3mobH8f9GcJlIh0ONVjIbmkhUn3VjdTK+hMnq7h0aLxZkJT3IrXE3IBdtdxkaz6xcAWnJ/X6iV4vSFP6XatY/3immiaLGdXcuthWMdelY6XqRp9XBsduF1fMCKlzzfzYBpOp4wz6okfYUvxeP68mc84v0NnnSJp9mixKz6Ci0Ny24OOACfMWkUXZ7ZJbfGAgKszZmz5V65vSjIYmzoRmndWKWc6rq5uRlYWcBGRpYatQ8o3OFGNawXXR5Fnb3sJHS4xjrBorewZhpSjWAqHqb4qmGKfjOTRN2sKh6ej03Lp4n06zgZBM1vs0BqY9sjLMTMwLnU6cTyZ1dFxvvR7TuXfDbiPpmbKtPsZFZZOrVffwCCUuT40+jvmS5rltb5FUdbQiM5X8dpFTZub8erN7Yc9AFcqqrkYNqgj7lI8HZisGS05zia5gwFryPIMgzHLn0qs+l6/KnUlVJZIQWBXygmwBw+QtGpqKTYJnlrOZkj0vXcFp/2GNtsJIa56mo+PDG/c6fAlhZvU9gNQo3kdfNjl4ncM8Co5BiiKskYRnVBZFcbZ8aX4zjJCLobAoyGkvnt0xWlXtcufUGsfcKyK3mGLHH1ULqeSLtYvKtdi3bE3dfCIzleu77N4uMTY0eeNe1i4iXlFzvw86Y9Xuy3CmvNZUwhtOQmAaBqjMOssUY3bo9QVXqpMg1Gfl4JbJV+nlPGW3gjTOrHSlDyvQzBEm0u4OJr5waGXPwKmDKtjtIX59KMZqzoWXK1VZ5vs0iSP2277Tfj2Oqi/5RZJoIT3fyOVTqwou5cmvzcOvYteUo8PuOE3ftPb4iThRN2y97mFUzEKiy2nnyS1UoFjXmoEWnhmfLJorzsPM+uXacjK4tLQP9CLbCkW37HQOykmjbA21djJtIaobDxJ7DKJ41VJivMisJV9/25xEH2MKqL6na2PrI6OpIFWoTjg7IPTJvbSanTfv7ORVvaSMbs9sCxi1v2f3Ahau4DD5vjd52yrp9v5dYnYcCFXy2co8NmGvC1N23ZscvM5hXs39gUJ2UirfgzzHM5hphHII1ihmBXitB0kjkRcZ0rSEZep7WLqv5VVvXvzkvPNwf+92ufqo2TzqnqsnRxZrl3mFBM4LGqrvUy10O4qiOQHKTZGsm1hjAoly088Y2x1RSrdFOJPNFPhoy1Rl6G9Lfx0rA5lBOqOTN5g4udxbb4RU4bWTSvmyd4iKlBuJX53ysbjD1RgILyEZGOtNBno9VXM46IwLdjdbF370WXkGo6elyEzPafradhTUlQG3abJLy2Ksvj06Pozj/eTl+XgyGb2s70VR9ZlYIZj1ysN8I+DgKew4EFbRKq2JdMw3p0fJfNxwtU3zSCV+xjfr4ZySowYJsK3QJCZLZWOEnUx7BpkKl2OyZrbUZCqYWXwmysi3lHdrR3q62w6YMp7aUpjMFRxmtJMxI00go2Vdlsa5B2fNvZ1y8/ngfDwaPk/2493klLzb6Umdr/wvXMGLdvUXWiBQF6TT/sN4/2e+ZOCO+LaGLmF3ndPxs+3mVqJmXTtqwiqx/S3HTf7EExmMchfs4oyRzDRCUQB1MWsQoCxKLFNBANf7dagiySkxKZtB30PEss8PvuscxvGhaCMnsekLzgk6XK3QbAGMd40gED6xybobVYiMsXMv+0wl/aotzNlpYscOhZpKQ6FboJeGo2gul8bgFEGH7se2XqdRqNxZnoGYC2wJs7eHG/ihm9H87JLhlT0Dl485tkBIvlxJhzWdcmjy1EXCotUfmicHyVG41VTX8aIAuY59UNYP45kRJCuBhGQtdNbci/aaZ7poOsU3cusTocCsEZAYmY6kc7OidZz2B4PL+CZZkdAMvG5Xl+tX2oXilES/1a0sBlDjwKp4XTs2djtDgOsZZDUwSur0lJL8aOYZqHLsbza6qa5bPtDrFkZyVpQ9l4hIYUJaeQPV45Odyktvci4emnQfHHb4k4RnzdKPfbqJ8IAZ8+IVHD+rMmMmvYjwHbYIsaiuXhfmduL4i/mys55iDRf5qeWZzHh4Cy5lhK53rmukA5kmvG8qQ1I3nrWhUpVDLsW82sjzo/bdKLq7QnOQmHnDjt1hosY/XK+IhIStmjq+XCfwqqnmXVVRSsA641zFzPLDUpzdxhKGbfdiV0OlqfyedZaE0yhnWjm7wuS+oz8+KCPJCqJ6hS1cyQ8Yjz5la5v13KwpszUDMjxKLz9cNy9zsYiVPQO7AXSh7rhvlHZs0zl07EnLKxCY9KpRdPhM35cV9s0cBel5JA1FT7e3VQVtmpPegyi63zU7B9JR+05wRp+tm2MiWcezrMQf1AQVkUbrY7b+kR0X/jA/tNioofb/lw/MgiEf8QO9iA/QrsMuWkEQtrqWcHQsCIZilkWlH3ca8jYk8wysJpM5Lc5C4WzVV61DWAkoj602xQgrDWhF8QHLpFJC8aYqS4Wm7orUqHO/OTxrVtnl8uIVnPYf1p13aYx+obdzSdd5GaPysAitVCE+Xo+GALjIKKZ6SmbVvAgeLmaEonR1GZDt3ih3Lsfj7PaZ6C9m0hLaB+Y8aTZkHlb1vcrOiThr7kZR/FWpdEf+HbbfUo5l2mVOSXNPmz4bSkpnnT7ijQkCndVJrd7HZweC5kCWfdPvWcreXM4Ub1mRm2DeZZWnP6u3Ec6qYBubdMjYSOtf5QagZWXY8tn05A/xVh1ldmke1ByiazjtwqqxcPAqPQO7YqqZmcoMPYstGqRNBqX2hUo+7dcsRyHrt9oQpTV4NkRNKNqYjLvMV/aE58GXc1VJM79Nw+tkeVbCq6/TaH2MZ6AFuR3M6oo6FUlQHz29DRKrN1JllWVnJWpQmYuqhAd6kd1PXKSKgBMvlWeliNFEKCo1sdIza6H48IfVjoYVVaksL8cr4NhqK09cC9EAzdDPouSjE2E9sliLsJV10YNBY798wN+jJeuyUAXFJgOrYOH7PmC7ZsXZYkYlkrJGkYKtJrPwciOcCU2c9AY4ZRvKCE1xGrJVnDdJe0ZIZizzZt4Ga3eKUYOVOJuc5uif6UNny8cd1omkgov8zwrKzbJAu+TKKHhCVNZGbXLanGW8PyaITsqQmvwU4nWxzyzFOWvBeXaVV6PZfoOyHL5ob9m5qJDX9M5oIy1EX7WySmv5Xm/KbmSwtCaoqkxDJYUzc83GxvyaGgnzQkt6Bnljc6FpiiAAAAd6SURBVKhxcuzDBzFP19nnhz/tRhG7KtKOwptW7flEUCZNiJ0eTdxri+yCXnsGarKkkifPK9Etd8fWbJUyl99tpxwr0SZCQimNKF0HPM/ABpjZhN0AXH+5ZNKR10OX44HFQc0xrD4cFIVVLfxRwLn45omZPGuw1trKOUAcunZiFcQqmyPfdEWV0amUSZBp5YxxVETOmhDre1lekdiZwFS5vNLrCY9+Kcd0QyH7qIIWqeBFu/RIXc1LMVSFuPZKSxWxjLNylWyTMh5ktsTinlZ24liF0t36zmlKnYaMX3zUPK3PiABl133Zbs08yV78uHNssNBZWd6pXjkwRRJ2XZzpoSKBHKnNWZOraIg2RWnv3Mu0ULt4uReMENh1O9qZg++pVAbJk5JxZh1ETWOSbc5/0/0X5WyZgVDBa2Vv8OSaFvUM9ABCfOy+r09puU6Mn0WlFCNJxkQy16MNnWIbDCmH6hFO6+gsUqoG7iRTZRb5XtIzKCJ6Thrb1sOJi6TJckpk4qEsihl17sXSURgeVWk6PE3MJMQ6sGdDJEdMqJPu/ajyXN1MeNc53CnJjWBhVYOx1ELG4lUSZ0CX0Y7pBNI43U+OYtpAvYqo0sy3Y6zUW5TrECiOBCpQXLijBokvNiirjKKllGSjnRdS6cUJZgmy4qHxRaIedw7kROJUyq2+rTYl1q63q4vT8UgZZ2igHJbCroisV+v2CpzPjxof8y0Cy1Rw/KwS364PPqgyPo46926UHjuPJgjvjVWNt7vKyb5Zo7BYFbStQsVa37Pk50Dm+S3gdnF5kq0sShazKOaC2AL1LXzZZVw5ciwOWLXTr1WRge9h83a0/9RsCFXPW1NSqaE2nrzaBaQuEyV66CKTikvDKdQlST1F10Wk5X1T9sRsaHIlBzgHtPX5uHJsDWedJTtMEnkD15m5tZBAR+A1mtn3hXzjnPIpQ5+igHPRklEKDYN6VFf6SWiBmUglCH2v7hk4DSMO1eJGqEQVF6CpTqlvauBAZ1On+bdY6r+xc2Pvfqtz3KzeT/qvO4fxXv1JUjka8ssiRyYdep9svnzXq90t146azUeV/W+THt8UxosOhyUH3y2Qiz9OvEjMaxqCY3WnLIGZz/zO4OnlGCs/T3KUl5DFc1BceKAXZZbHOAaGFSrCHg64An7YTs+AcGVYNr92TqXo0P1kzOUpNiswud6GLEesSRogY07m3JLgCXLD6j0EbgJHkxkVJAm9t93KHyv1o2bzqHb49WHzxFvbXMaoXJ30MbcfHekEcprSSZVzSNoyo13KCEkB+lhNT+0o3495OfYYCf9PvT0z00wUnd1xcCyf2W1ONVj0+35yd6/8sNk8qlcPKoluoLW2CysvL+gM6XnJdPy89It5BplY0wq6nCBninSGU2t5Uua2Bk8tUAVmnSX43Dyol7njGOnA0yy3z0AOEUyOJZYgO0O0Ul99Cz56cVfFqoHRawWVIPy9gmcgemb2YJjbhbJByiXIdSjQZ2Y1GBclLlvlJgPxRJbyBOiFISqs0jsDljc2uQ1AAvWVlhIy+1sON7zuagASI45rWKxfyaaVqbIhRpxV+dS9AGtMdIRnadUXU0OZiNGeCed+iUhAYrM3kChZoW+Sb9scZcyUt+cqrwijSBZi+jiDr7QWeqvMvI8Zmql01pe86mdqM/5aIWXbqjDWXVWa2dhVRqaATUmJKfA97dfsR2xUnoIVpHcd0psMKJvoH0F7FlXWuGbXjhmV0iX7tlpcS3MSceF5aZws4tA2D6cf2XgXN0Kjea5KqntSAoVL1kVlEUK4ndtahSrlxX2YWKOWKkim4+i0jelAfrt4pcyKCPWIQHpDzJ+breQeBD2wZ9O/09kX4axF8RJ16xv5nvegF4EEPde3MNKIv+7+osqBkdl0c1aibpb8gH4/gSmPQkaIGc3sFHTkdgc16jop1bjntYKTzjlc0jOgAZp3AEeqOhR2nAOdiOecyrKrKilpM75pk4HaZT0j2WdxigxCjUQbrBC1XYEm3qAGXPR8a+GpP8VwcAgrpOhpEluP2BTKZCVSbzKwIq2DKzIqq8zrP+Bjqx79g2rJlO54JUZwJ6NIqQb05Rs90+Ja2sWqQhDHipH5WJbkvKI+s7Ibz2DjWGapMeec8tJCI7byJl3rnS1ySc9gttArPyvabMXR88qVRoEgUITA6Glp4SdibLn+mwzs8zgCARAAAYvA5+EZDJM4rr5UuwWtCuIABLabwKBR6b5fqQqjF73zlQQgMwiAwJdF4PPwDL6sNkNtQQAEQAAEQGBzBOAZbI4tJIMACIAACIDA9hGAZ7B9bQaNQQAEQAAEQGBzBOAZbI4tJIMACIAACIDA9hGAZ7B9bQaNQQAEQAAEQGBzBOAZbI4tJIMACIAACIDA9hGAZ7B9bQaNQQAEQAAEQGBzBOAZbI4tJIMACIAACIDA9hGAZ7B9bQaNQQAEQAAEQGBzBOAZbI4tJIMACIAACIDA9hGAZ7B9bQaNQQAEQAAEQGBzBOAZbI4tJIMACIAACIDA9hGAZ7B9bQaNQQAEQAAEQGBzBP4/+4b4cB47GrgAAAAASUVORK5CYII="
    },
    "855e9b44-29d5-4162-8a54-cd363f2e8627.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "89c602bc-c593-4190-a643-9668cf471193",
   "metadata": {},
   "source": [
    "---\n",
    "残差连接和层规范化\n",
    "\n",
    "在Transformer中，残差连接和层规范化是构建有效深度架构的关键组件。它们在每个子层中起到至关重要的作用，以确保信息的稳定传递和训练的有效性。\n",
    "\n",
    "残差连接\n",
    "\n",
    "残差连接最初是在ResNet中提出的，目的是解决深度神经网络训练中的梯度消失和梯度爆炸问题。在残差连接中，输入直接跳过一个或多个层，并与这些层的输出相加。这种连接方式允许梯度在反向传播时直接传回输入层，从而缓解了梯度消失的问题。\n",
    "\n",
    "![image.png](attachment:855e9b44-29d5-4162-8a54-cd363f2e8627.png)\n",
    "\n",
    "层规范化\n",
    "\n",
    "层规范化（Layer Normalization）和批量规范化（Batch Normalization）都是用于加速训练和提高模型稳定性的技术。与批量规范化不同，层规范化是基于特征维度进行规范化的，这使得它在自然语言处理任务中效果更好，因为输入通常是变长序列。\n",
    "\n",
    "![image.png](attachment:69e88468-a456-455b-a19b-f43a68cb9dcc.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c670dbb-52ab-4280-a3ba-ed887a77cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer norm: tensor([[-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>) \n",
      "batch norm: tensor([[-1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)\n",
    "X = torch.tensor(\n",
    "    [\n",
    "        [1, 2], [2, 3]\n",
    "    ], dtype=torch.float32\n",
    ")\n",
    "\n",
    "print(\"layer norm:\", ln(X), '\\nbatch norm:', bn(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ef04f3-17c7-478e-b9ca-4783bcc41dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    残差连接后进行层规范化\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        '''\n",
    "        定义dropout层\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        '''\n",
    "        定义层规范化\n",
    "        '''\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "    def forward(self, X, Y):\n",
    "        '''\n",
    "        残差连接后进行层规范化\n",
    "        '''\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4411656-cc99-4472-9ef6-fb3e66974573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm([3,4], 0.5)\n",
    "add_norm.eval()\n",
    "add_norm(\n",
    "    torch.ones((2, 3, 4)),\n",
    "    torch.ones((2, 3, 4))\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54642faa-2bb2-46bc-81e6-acf4536f2d63",
   "metadata": {},
   "source": [
    "通过这种方式，残差连接和层规范化能够在保持信息流动和稳定训练的同时，使模型更深层次的特征表达成为可能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50daeb1b-1e48-4aa8-964e-8c81f793ac19",
   "metadata": {},
   "source": [
    "Transformer编码器\n",
    "\n",
    "在这一部分，将实现Transformer的编码器部分。编码器由多个相同的编码器层（`EncoderBlock`）堆叠而成。每个编码器层包含两个主要子层：多头自注意力（Multi-Head Self-Attention）和基于位置的前馈网络（Position-Wise Feed-Forward Network）。这两个子层都使用了残差连接和层规范化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32d35be4-6e99-45fb-aa4a-65263cfa17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "`EncoderBlock`类实现了Transformer编码器的一个层。\n",
    "它包含两个主要子层：\n",
    "    多头自注意力和基于位置的前馈网络，\n",
    "    这两个子层都使用了残差连接和层规范化。\n",
    "'''\n",
    "class EncoderBlock(nn.Module):\n",
    "    '''\n",
    "    Transformer 编码器\n",
    "    '''\n",
    "    def __init__(\n",
    "        self, \n",
    "        key_size, \n",
    "        query_size, \n",
    "        value_size, \n",
    "        num_hiddens,\n",
    "        norm_shape,\n",
    "        ffn_num_input,\n",
    "        ffn_num_hiddens, \n",
    "        num_heads,\n",
    "        dropout,\n",
    "        use_bias=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        '''\n",
    "        - `self.attention`：多头自注意力层。用于在输入序列的不同位置之间计算相关性。\n",
    "        '''\n",
    "        self.attention = d2l.MultiHeadAttention(\n",
    "            key_size, \n",
    "            query_size, \n",
    "            value_size, \n",
    "            num_hiddens,\n",
    "            num_heads, \n",
    "            dropout,\n",
    "            use_bias\n",
    "        )\n",
    "        '''\n",
    "        - `self.addnorm1`：第一个残差连接和层规范化模块，包含多头自注意力层的输出和输入的残差连接。\n",
    "        '''\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        '''\n",
    "        - `self.ffn`：基于位置的前馈网络。对每个位置的表示进行变换。\n",
    "        '''\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, \n",
    "            ffn_num_hiddens,\n",
    "            num_hiddens\n",
    "        )\n",
    "        '''\n",
    "        - `self.addnorm2`：第二个残差连接和层规范化模块，包含前馈网络的输出和输入的残差连接。\n",
    "        '''\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "    def forward(self, X, valid_lens):\n",
    "        '''\n",
    "        1. 计算多头自注意力的输出，并通过残差连接和层规范化（`addnorm1`）。\n",
    "        2. 计算前馈网络的输出，并通过残差连接和层规范化（`addnorm2`）。\n",
    "        '''\n",
    "        Y = self.addnorm1(\n",
    "            X, self.attention(X, X, X, valid_lens)\n",
    "        )\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e4d5f1-aee7-45ef-ab56-0dde4843bcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- 输入`X`的形状为`(2, 100, 24)`，\n",
    "    表示批量大小为2，每个序列有100个时间步，每个时间步有24个特征。\n",
    "\n",
    "- `valid_lens`表示有效长度。\n",
    "- `EncoderBlock`实例化一个编码器块，并将输入`X`和`valid_lens`传入，\n",
    "    得到输出`output`的形状为`(2, 100, 24)`，与输入形状相同。\n",
    "\n",
    "'''\n",
    "X = torch.ones((2, 100, 24))\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "encoder_blk = EncoderBlock(\n",
    "    24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5 \n",
    ")\n",
    "encoder_blk.eval()\n",
    "encoder_blk(X, valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61e94c6e-c0ce-42f0-b711-23f325ed2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TransformerEncoder类\n",
    "\n",
    "`TransformerEncoder`类是整个Transformer编码器的实现，它由多个`EncoderBlock`实例堆叠而成。\n",
    "'''\n",
    "class TransformerEncoder(d2l.Encoder):\n",
    "    '''\n",
    "    Transformer编码器\n",
    "    '''\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size, \n",
    "        key_size, \n",
    "        query_size, \n",
    "        value_size,\n",
    "        num_hiddens,\n",
    "        norm_shape,\n",
    "        ffn_num_input,\n",
    "        ffn_num_hiddens,\n",
    "        num_heads,\n",
    "        num_layers,\n",
    "        dropout,\n",
    "        use_bias=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        '''\n",
    "        - `self.embedding`：词嵌入层。将输入的词索引转换为词向量。\n",
    "        '''\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        '''\n",
    "        - `self.pos_encoding`：位置编码层。为每个词向量添加位置信息，以捕捉序列中的顺序信息。\n",
    "        '''\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        '''\n",
    "        - `self.blks`：一个包含多个`EncoderBlock`实例的顺序容器（`nn.Sequential`）。每个`EncoderBlock`都是一个Transformer编码器层。\n",
    "        '''\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\n",
    "                \"block\"+str(i),\n",
    "                EncoderBlock(\n",
    "                    key_size,\n",
    "                    query_size,\n",
    "                    value_size,\n",
    "                    num_hiddens,\n",
    "                    norm_shape, \n",
    "                    ffn_num_input,\n",
    "                    ffn_num_hiddens,\n",
    "                    num_heads,\n",
    "                    dropout,\n",
    "                    use_bias\n",
    "                )\n",
    "            )\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        '''\n",
    "        因为位置编码值在-1和1之间，\n",
    "        因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        然后再与位置编码相加。\n",
    "\n",
    "        1. 输入`X`经过词嵌入层得到词向量。\n",
    "        2. 将词向量乘以嵌入维度的平方根进行缩放，然后加上位置编码。\n",
    "        '''\n",
    "        X = self.pos_encoding(\n",
    "            self.embedding(X) * math.sqrt(self.num_hiddens)\n",
    "        )\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        '''\n",
    "        3. 依次通过每个编码器层`blk`，得到最终的编码器输出。\n",
    "        '''\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        return X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9dd976d-9107-4a7a-b2cc-3280c867530c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoder = TransformerEncoder(\n",
    "    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5\n",
    ")\n",
    "encoder.eval()\n",
    "encoder(\n",
    "    torch.ones(\n",
    "        (2, 100),\n",
    "        dtype=torch.long\n",
    "    ),\n",
    "    valid_lens\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f8222-ffc2-4f7d-8f7f-2b89a51fdd23",
   "metadata": {},
   "source": [
    "- `EncoderBlock`类实现了Transformer编码器的一个层，包括多头自注意力和基于位置的前馈网络。\n",
    "- `TransformerEncoder`类堆叠了多个`EncoderBlock`实例，实现了整个Transformer编码器。\n",
    "- 在实际应用中，Transformer编码器可以处理各种序列数据，如文本、图像和语音等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbd1f3-996b-42a1-878f-189255e65e7c",
   "metadata": {},
   "source": [
    "---\n",
    "解码器\n",
    "\n",
    "在Transformer模型中，解码器用于生成输出序列。与编码器类似，解码器也是由多个相同的层组成，每层包含三个子层：解码器自注意力、多头“编码器-解码器”注意力、和基于位置的前馈网络。每个子层都使用残差连接和紧随的层规范化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60f019b7-59bb-4a1e-b31d-3d469869cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "`DecoderBlock`类实现了Transformer解码器的一个层。它包含三个主要子层：\n",
    "\n",
    "- 解码器自注意力（Masked Multi-Head Self-Attention）\n",
    "- 多头“编码器-解码器”注意力（Multi-Head Encoder-Decoder Attention）\n",
    "- 基于位置的前馈网络（Position-Wise Feed-Forward Network）\n",
    "\n",
    "这些子层都使用了残差连接和层规范化。\n",
    "'''\n",
    "class DecoderBlock(nn.Module):\n",
    "    '''\n",
    "    解码器中1个块\n",
    "    '''\n",
    "    def __init__(\n",
    "        self, \n",
    "        key_size, \n",
    "        query_size, \n",
    "        value_size, \n",
    "        num_hiddens,\n",
    "        norm_shape,\n",
    "        ffn_num_input,\n",
    "        ffn_num_hiddens,\n",
    "        num_heads,\n",
    "        dropout,\n",
    "        i,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        '''\n",
    "        - `self.attention1`：\n",
    "            掩蔽多头自注意力层，确保查询位置只会与之前生成的词元位置进行注意力计算。\n",
    "        - `self.addnorm1`：\n",
    "            残差连接和层规范化模块，包含多头自注意力层的输出和输入的残差连接。\n",
    "        - `self.attention2`：\n",
    "            多头“编码器-解码器”注意力层，查询来自解码器的输出，键和值来自编码器的输出。\n",
    "        - `self.addnorm2`：\n",
    "            残差连接和层规范化模块，包含多头“编码器-解码器”注意力层的输出和输入的残差连接。\n",
    "        - `self.ffn`：\n",
    "            基于位置的前馈网络，对每个位置的表示进行变换。\n",
    "        - `self.addnorm3`：\n",
    "            残差连接和层规范化模块，包含前馈网络的输出和输入的残差连接。\n",
    "\n",
    "        '''\n",
    "        self.attention1 = d2l.MultiHeadAttention(\n",
    "            key_size, \n",
    "            query_size, \n",
    "            value_size, \n",
    "            num_hiddens,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "        )\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = d2l.MultiHeadAttention(\n",
    "            key_size, \n",
    "            query_size, \n",
    "            value_size, \n",
    "            num_hiddens,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "        )\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input,\n",
    "            ffn_num_hiddens,\n",
    "            num_hiddens\n",
    "        )\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        '''\n",
    "        1. 处理解码器的输入，考虑训练和预测阶段的不同处理方式。\n",
    "        2. 计算掩蔽多头自注意力的输出，并通过残差连接和层规范化（`addnorm1`）。\n",
    "        3. 计算多头“编码器-解码器”注意力的输出，并通过残差连接和层规范化（`addnorm2`）。\n",
    "        4. 计算前馈网络的输出，并通过残差连接和层规范化（`addnorm3`）。\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        从state中提取编码器的输出和有效长度。\n",
    "        '''\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        '''\n",
    "        判断当前层的state是否为空。\n",
    "        '''\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            '''\n",
    "            将之前生成的词元和当前输入进行拼接，形成key_values。\n",
    "            '''\n",
    "            key_values = torch.cat(\n",
    "                (\n",
    "                    state[2][self.i], X\n",
    "                ), axis = 1\n",
    "            )\n",
    "        '''\n",
    "        更新当前层的state。\n",
    "        '''\n",
    "        state[2][self.i] = key_values\n",
    "        '''\n",
    "        在训练阶段，计算解码器的有效长度。\n",
    "        '''\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            '''\n",
    "            生成解码器的有效长度。\n",
    "            '''\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device\n",
    "            ).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "        '''\n",
    "        自注意力\n",
    "\n",
    "        计算掩蔽多头自注意力的输出。\n",
    "        '''\n",
    "        X2 = self.attention1(\n",
    "            X, key_values, key_values, dec_valid_lens\n",
    "        )\n",
    "        '''\n",
    "        通过残差连接和层规范化。\n",
    "        '''\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        '''\n",
    "        计算多头“编码器-解码器”注意力的输出。\n",
    "        '''\n",
    "        Y2 = self.attention2(\n",
    "            Y, enc_outputs, enc_outputs, enc_valid_lens\n",
    "        )\n",
    "        '''\n",
    "        通过残差连接和层规范化。\n",
    "        '''\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        '''\n",
    "        计算前馈网络的输出，并通过残差连接和层规范化，返回输出和state。\n",
    "        '''\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9657b52f-a2fd-4033-8ef3-aa2cd553dec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_blk = DecoderBlock(\n",
    "    24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0\n",
    ")\n",
    "decoder_blk.eval()\n",
    "'''\n",
    "输入`X`的形状为`(2, 100, 24)`，表示批量大小为2，每个序列有100个时间步，每个时间步有24个特征。\n",
    "'''\n",
    "X = torch.ones((2, 100, 24))\n",
    "'''\n",
    "`state`包含编码器的输出、有效长度和解码器每一层的状态。\n",
    "'''\n",
    "state = [\n",
    "    encoder_blk(X, valid_lens),\n",
    "    valid_lens,\n",
    "    [None]\n",
    "]\n",
    "'''\n",
    "`DecoderBlock`实例化一个解码器块，并将输入`X`和`state`传入，\n",
    "得到输出`output`的形状为`(2, 100, 24)`，与输入形状相同。\n",
    "'''\n",
    "decoder_blk(X, state)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76ec64-d6ac-4517-a710-aacb5eb0ad73",
   "metadata": {},
   "source": [
    "- `DecoderBlock`类实现了Transformer解码器的一个层，包括掩蔽多头自注意力、多头“编码器-解码器”注意力和基于位置的前馈网络。\n",
    "- `TransformerDecoder`类堆叠了多个`DecoderBlock`实例，实现了整个Transformer解码器。\n",
    "- 在实际应用中，Transformer解码器可以用于各种序列生成任务，如机器翻译和文本生成等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5bc618-ddf2-40b2-854f-04d9df0564ed",
   "metadata": {},
   "source": [
    "---\n",
    "`TransformerDecoder`类是整个Transformer解码器的实现，它由多个`DecoderBlock`实例堆叠而成。最后，通过一个全连接层计算所有词汇表大小的可能输出词元的预测值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70922507-e439-46ff-a837-4048d9f19be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(d2l.AttentionDecoder):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size,\n",
    "        key_size, \n",
    "        query_size, \n",
    "        value_size, \n",
    "        num_hiddens,\n",
    "        norm_shape,\n",
    "        ffn_num_input,\n",
    "        ffn_num_hiddens,\n",
    "        num_heads,\n",
    "        num_layers,\n",
    "        dropout,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        '''\n",
    "        词嵌入层，将输入的词索引转换为词向量。\n",
    "        '''\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        '''\n",
    "        位置编码层，为每个词向量添加位置信息。\n",
    "        '''\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        '''\n",
    "        一个包含多个`DecoderBlock`实例的顺序容器，每个`DecoderBlock`都是一个Transformer解码器层。\n",
    "        '''\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\n",
    "                'block'+str(i),\n",
    "                DecoderBlock(\n",
    "                    key_size,\n",
    "                    query_size,\n",
    "                    value_size,\n",
    "                    num_hiddens,\n",
    "                    norm_shape,\n",
    "                    ffn_num_input,\n",
    "                    ffn_num_hiddens,\n",
    "                    num_heads,\n",
    "                    dropout,\n",
    "                    i\n",
    "                )\n",
    "            )\n",
    "        '''\n",
    "        全连接层，将解码器输出转换为词汇表大小的预测分布。\n",
    "        '''\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [\n",
    "            enc_outputs, enc_valid_lens, [None] * self.num_layers\n",
    "        ]\n",
    "    def forward(self, X, state):\n",
    "        '''\n",
    "        1. 输入`X`经过词嵌入层得到词向量，并加上位置编码。\n",
    "        2. 依次通过每个解码器层`blk`，得到最终的解码器输出。\n",
    "        3. 将解码器输出通过全连接层，得到词汇表大小的预测分布。\n",
    "        '''\n",
    "        '''\n",
    "        输入`X`经过词嵌入层得到词向量，并加上位置编码。\n",
    "        '''\n",
    "        X = self.pos_encoding(\n",
    "            self.embedding(X) * math.sqrt(self.num_hiddens)\n",
    "        )\n",
    "        '''\n",
    "        初始化解码器的注意力权重。\n",
    "        '''\n",
    "        self._attention_weigths = [\n",
    "            [None] * len(self.blks) for _ in range (2)\n",
    "        ]\n",
    "        '''\n",
    "        依次通过每个解码器层`blk`，得到最终的解码器输出。\n",
    "        '''\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            '''\n",
    "            存储解码器自注意力的权重。\n",
    "            '''\n",
    "            self._attention_weigths[0][i] = blk.attention1.attention.attention_weights\n",
    "            '''\n",
    "            存储多头“编码器-解码器”注意力的权重。\n",
    "            '''\n",
    "            self._attention_weigths[1][i] = blk.attention2.attention.attention_weights\n",
    "        '''\n",
    "        将解码器输出通过全连接层，得到词汇表大小的预测分布，并返回状态`state`。\n",
    "        '''\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self.attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9d47f-1c94-4d1e-b720-c24e5aa3aedc",
   "metadata": {},
   "source": [
    "---\n",
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19e8a59-55db-4368-9d27-2b86db12539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, d2l.try_gpu()\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ce3aff-ffc2-4d4c-8f6d-29cea49b17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(\n",
    "    batch_size, num_steps\n",
    ")\n",
    "\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab),\n",
    "    key_size, \n",
    "    query_size, \n",
    "    value_size, \n",
    "    num_hiddens,\n",
    "    norm_shape,\n",
    "    ffn_num_input,\n",
    "    ffn_num_hiddens,\n",
    "    num_heads,\n",
    "    num_layers,\n",
    "    dropout\n",
    ")\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab),\n",
    "    key_size, \n",
    "    query_size, \n",
    "    value_size, \n",
    "    num_hiddens,\n",
    "    norm_shape,\n",
    "    ffn_num_input,\n",
    "    ffn_num_hiddens,\n",
    "    num_heads,\n",
    "    num_layers,\n",
    "    dropout\n",
    ")\n",
    "\n",
    "net = d2l.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1de13765-b8b8-4c5b-abfb-cb8f309b94be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.030, 9373.9 tokens/sec on cuda:0\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"262.1875pt\" height=\"183.35625pt\" viewBox=\"0 0 262.1875 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-07-17T15:42:34.762234</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 262.1875 183.35625 \n",
       "L 262.1875 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 145.8 \n",
       "L 245.44375 145.8 \n",
       "L 245.44375 7.2 \n",
       "L 50.14375 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 91.259539 145.8 \n",
       "L 91.259539 7.2 \n",
       "\" clip-path=\"url(#p8959c5206c)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"mbae5ac23d2\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbae5ac23d2\" x=\"91.259539\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(84.897039 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 142.654276 145.8 \n",
       "L 142.654276 7.2 \n",
       "\" clip-path=\"url(#p8959c5206c)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbae5ac23d2\" x=\"142.654276\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(133.110526 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 194.049013 145.8 \n",
       "L 194.049013 7.2 \n",
       "\" clip-path=\"url(#p8959c5206c)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbae5ac23d2\" x=\"194.049013\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(184.505263 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 245.44375 145.8 \n",
       "L 245.44375 7.2 \n",
       "\" clip-path=\"url(#p8959c5206c)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbae5ac23d2\" x=\"245.44375\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(235.9 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_5\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(132.565625 174.076563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 50.14375 122.356796 \n",
       "L 245.44375 122.356796 \n",
       "\" clip-path=\"url(#p8959c5206c)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <defs>\n",
       "       <path id=\"mfdbab13a3a\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfdbab13a3a\" x=\"50.14375\" y=\"122.356796\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.878125 126.156014) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 50.14375 80.25586 \n",
       "L 245.44375 80.25586 \n",
       "\" clip-path=\"url(#p8959c5206c)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfdbab13a3a\" x=\"50.14375\" y=\"80.25586\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.878125 84.055079) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 50.14375 38.154925 \n",
       "L 245.44375 38.154925 \n",
       "\" clip-path=\"url(#p8959c5206c)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mfdbab13a3a\" x=\"50.14375\" y=\"38.154925\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.878125 41.954144) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(14.798437 86.157813) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 50.14375 13.5 \n",
       "L 60.422697 58.378181 \n",
       "L 70.701645 84.567005 \n",
       "L 80.980592 101.231031 \n",
       "L 91.259539 111.849557 \n",
       "L 101.538487 118.692227 \n",
       "L 111.817434 124.409354 \n",
       "L 122.096382 127.134194 \n",
       "L 132.375329 126.422698 \n",
       "L 142.654276 128.64728 \n",
       "L 152.933224 132.528505 \n",
       "L 163.212171 131.434483 \n",
       "L 173.491118 132.683875 \n",
       "L 183.770066 136.064662 \n",
       "L 194.049013 135.353227 \n",
       "L 204.327961 136.750148 \n",
       "L 214.606908 137.019585 \n",
       "L 224.885855 137.487575 \n",
       "L 235.164803 138.055811 \n",
       "L 245.44375 139.5 \n",
       "\" clip-path=\"url(#p8959c5206c)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 145.8 \n",
       "L 50.14375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 245.44375 145.8 \n",
       "L 245.44375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 145.8 \n",
       "L 245.44375 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 7.2 \n",
       "L 245.44375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p8959c5206c\">\n",
       "   <rect x=\"50.14375\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2l.train_seq2seq(\n",
    "    net, train_iter, lr, num_epochs, tgt_vocab, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c417f82-826d-436a-8fb6-bc296eba0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = d2l.predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device, True\n",
    "    )\n",
    "    print(\n",
    "        f'{eng} => {translation}, ',\n",
    "          f'bleu {d2l.bleu(translation, fra, k=2):.3f}'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ae73a-53d2-494f-b324-bec5a48a9983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
