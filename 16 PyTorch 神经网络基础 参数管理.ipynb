{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d2cedba-d531-417f-96d9-9262eead76c0",
   "metadata": {},
   "source": [
    "参数管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff3ebd-7347-48b0-8c9e-2663a91ac770",
   "metadata": {},
   "source": [
    "首先关注具有单隐藏层的多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e483d1-396c-4adb-8aaa-e9fea6e65047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a6404b-1f7b-4d9b-8f49-72c7ebb989a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714e58d0-a2f6-41d0-bc14-b98058a371bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4454],\n",
       "        [-0.3780]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(size=(2,4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98438d45-2a63-4298-ac56-d86eedd0fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0217, 0.5857, 0.9076, 0.1539],\n",
      "        [0.6070, 0.2604, 0.5620, 0.1450]])\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46182817-2927-4ff2-a376-3c7b9e8bf314",
   "metadata": {},
   "source": [
    "参数访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c040aff-f6c1-46ed-9889-eec6adb12c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.2018, -0.1675, -0.2158, -0.2928, -0.1480, -0.3345, -0.3189,  0.1393]])), ('bias', tensor([-0.3052]))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe2229-05aa-4be1-b575-e22b5b391d68",
   "metadata": {},
   "source": [
    "目标参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f60cf76f-41f5-455b-a41a-102b90f501f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(net[2].bias): <class 'torch.nn.parameter.Parameter'> \n",
      "\n",
      "net[2].bias: \n",
      " Parameter containing:\n",
      "tensor([-0.3052], requires_grad=True) \n",
      "\n",
      "net[2].bias.data: \n",
      " tensor([-0.3052]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"type(net[2].bias):\",type(net[2].bias),\"\\n\")\n",
    "print(\"net[2].bias:\",\"\\n\",net[2].bias,\"\\n\")\n",
    "print(\"net[2].bias.data:\",\"\\n\",net[2].bias.data,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485dcecc-b0e8-43ea-a61c-fcbb1122826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad == None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e93fa-8fdc-48fe-9b3b-6b43ff704814",
   "metadata": {},
   "source": [
    "一次性访问所有参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd9c259a-330b-4f55-8d0d-a614cb872eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3445817-b1ef-4f2d-9932-ee805670f7f7",
   "metadata": {},
   "source": [
    "当然可以。\n",
    "\n",
    "首先，让我们回顾一下您给出的代码。您定义了一个简单的神经网络`net`，该网络由两个线性层（`nn.Linear`）和一个ReLU激活函数（`nn.ReLU`）组成。第一个线性层从4个输入特征映射到8个输出特征，第二个线性层从8个输入特征映射到1个输出特征。\n",
    "\n",
    "接着，您创建了一个2x4的随机输入张量`X`，并通过`net(X)`将其传递给网络。\n",
    "\n",
    "最后，您使用了一个列表推导式来打印网络第一个线性层的参数名称和形状。\n",
    "\n",
    "现在，我们来详细解释`print(*[(name, param.shape) for name, param in net[0].named_parameters()])`这行代码：\n",
    "\n",
    "1. **net[0].named_parameters()**：\n",
    "\n",
    "\n",
    "\t* `net[0]`：这是获取`net`中的第一个模块，即第一个线性层。\n",
    "\t* `named_parameters()`：这是一个方法，用于返回模块中所有参数的迭代器，其中每个参数都与其名称相关联。\n",
    "2. **for name, param in net[0].named_parameters()**：\n",
    "\n",
    "\n",
    "\t* 这是一个for循环，用于遍历`net[0]`（即第一个线性层）的所有参数。\n",
    "\t* 在每次迭代中，`name`是参数的名称（例如`weight`或`bias`），`param`是参数的实际值。\n",
    "3. **[(name, param.shape) for name, param in net[0].named_parameters()]**：\n",
    "\n",
    "\n",
    "\t* 这是一个列表推导式，用于创建一个新的列表。\n",
    "\t* 对于`net[0]`中的每个参数，它都会创建一个元组`(name, param.shape)`，其中`name`是参数的名称，`param.shape`是参数的形状。\n",
    "4. **print(*...)**：\n",
    "\n",
    "\n",
    "\t* `*`操作符是Python中的解包操作符。在这里，它用于将列表推导式生成的列表解包为单独的参数，以便`print`函数可以打印它们。\n",
    "\t* 因此，如果您有一个元组列表`[('weight', torch.Size([8, 4])), ('bias', torch.Size([8]))]`，则`print(*...)`将等同于`print('weight', torch.Size([8, 4]), 'bias', torch.Size([8]))`。\n",
    "\n",
    "综上所述，该行代码的目的是打印网络第一个线性层的所有参数的名称和形状。对于给定的网络结构，输出将是：\n",
    "\n",
    "\n",
    "```python\n",
    "weight torch.Size([8, 4]) bias torch.Size([8])\n",
    "```\n",
    "这表示第一个线性层有一个形状为[8, 4]的权重矩阵和一个形状为[8]的偏置向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff81afaf-1379-49d7-addc-347b55b0ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10ea8d6f-f6e1-4666-9921-fb909aaaf088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3052])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce535a4-0a87-4455-83ac-107d9ae14df8",
   "metadata": {},
   "source": [
    "从嵌套块收集参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96531b26-3625-4cf9-b5da-6d927b6e54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4,8), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(8,4),\n",
    "                         nn.ReLU()\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1fb40e0-63b2-43a0-8360-29d984cc90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block {i}', block1())\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e7ae255-5e84-4b48-8c4e-5f88f8e0a14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1036],\n",
       "        [0.1036]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet = nn.Sequential(block2(), nn.Linear(4,1))\n",
    "rgnet(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5558508-ab4b-49ab-8026-e3ce9b45cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea805967-8095-4e3d-9001-7c2bb0febdc2",
   "metadata": {},
   "source": [
    "内置初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a906579-023a-449a-a634-91578c2a0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be9d2117-138e-47a6-85ac-c76aecab5bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.apply(init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06ad9866-9cfc-4c0c-b2dd-a759fd56f4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0031, -0.0035,  0.0027,  0.0103]), tensor(0.))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19132e7-037f-475c-85e0-2f7bfc2e4b16",
   "metadata": {},
   "source": [
    "这些代码涉及PyTorch的神经网络初始化。我会为你详细解释每一部分。\n",
    "\n",
    "1. **定义初始化函数 `init_normal`**:\n",
    "\n",
    "\n",
    "```python\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "```\n",
    "这个函数的目的是为神经网络中的线性层（`nn.Linear`）设置特定的权重和偏置初始化。\n",
    "\n",
    "* `if type(m) == nn.Linear:`：这一行检查传入的模块`m`是否是线性层。\n",
    "* `nn.init.normal_(m.weight, mean=0, std=0.01)`：这一行将线性层的权重初始化为均值为0、标准差为0.01的正态分布。注意，`_`后缀表示这个操作会直接在`m.weight`上进行原地修改，而不是返回一个新的张量。\n",
    "* `nn.init.zeros_(m.bias)`：这一行将线性层的偏置初始化为0。同样，`_`后缀表示这是一个原地操作。\n",
    "2. **应用初始化函数**:\n",
    "\n",
    "\n",
    "```python\n",
    "net.apply(init_normal)\n",
    "```\n",
    "net.apply()`是一个方法，它会遍历网络中的每一个模块，并对每一个模块应用`init_normal`函数。这意味着网络中的所有线性层都将使用上述定义的初始化方法。\n",
    "\n",
    "3. **检查初始化后的权重和偏置**:\n",
    "\n",
    "\n",
    "```python\n",
    "net[0].weight.data[0], net[0].bias.data[0]\n",
    "```\n",
    "这一行代码会返回网络第一个线性层的第一个权重的值和第一个偏置的值。\n",
    "\n",
    "* `net[0]`：这表示网络的第一个模块，即第一个线性层。\n",
    "* `net[0].weight.data[0]`：这表示第一个线性层的权重的第一个元素。\n",
    "* `net[0].bias.data[0]`：这表示第一个线性层的偏置的第一个元素。\n",
    "\n",
    "综上所述，这些代码的目的是为网络中的所有线性层设置特定的权重和偏置初始化，并随后检查第一个线性层的初始化后的权重和偏置值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "529a2211-a1e3-4eb3-bab0-380fdc9f12f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78a9c64c-3fdc-4341-b4a7-a191af10727c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.apply(init_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ba8c934-1784-4de1-beed-164665cb64ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e950206-53f4-4be3-a6eb-3adcfd938c0b",
   "metadata": {},
   "source": [
    "当然可以。这段代码的目的是为了初始化神经网络中的某些层的权重和偏置。这里我们详细解释每一部分：\n",
    "\n",
    "1. **定义初始化函数**：\n",
    "\n",
    "\n",
    "```python\n",
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "```\n",
    "这个函数`init_constant`接收一个参数`m`，它代表网络中的一个模块或层。然后，该函数检查这个模块是否是线性层（即全连接层）。如果是，它将权重（`weight`）初始化为常数1，并将偏置（`bias`）初始化为0。\n",
    "\n",
    "* `nn.init.constant_(m.weight, 1)`：这行代码将`m`的权重初始化为常数1。注意，`_`后缀表示这是一个就地操作，它会直接修改输入参数`m.weight`的值，而不是返回一个新的张量。\n",
    "* `nn.init.zeros_(m.bias)`：这行代码将`m`的偏置初始化为0。同样，这也是一个就地操作。\n",
    "2. **应用初始化函数**：\n",
    "\n",
    "\n",
    "```python\n",
    "net.apply(init_constant)\n",
    "```\n",
    "这行代码将整个网络`net`的每一个模块或层都传递给`init_constant`函数进行初始化。`net.apply()`是一个方便的方法，它遍历网络中的每一个模块，并将每个模块作为参数传递给给定的函数。\n",
    "\n",
    "3. **检查初始化结果**：\n",
    "\n",
    "\n",
    "```python\n",
    "net[0].weight.data[0], net[0].bias.data[0]\n",
    "```\n",
    "这行代码检查网络`net`的第一个模块（通常是第一个层）的权重和偏置的第一个元素的值。由于我们使用了`init_constant`函数进行初始化，所以权重的第一个元素应该是1，偏置的第一个元素应该是0。\n",
    "\n",
    "总结：这段代码的目的是将神经网络`net`中的所有线性层的权重初始化为常数1，偏置初始化为0，并检查第一个线性层的权重和偏置的第一个元素的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc690d-2b1e-4260-bee9-f1680baeb7b5",
   "metadata": {},
   "source": [
    "为什么权重不建议设置为常识\n",
    "\n",
    "权重是机器学习模型中的一个关键参数，它决定了模型在训练过程中对不同数据点的重视程度。权重设置得是否合适，直接影响着模型的训练效果和泛化能力。在机器学习领域，通常不建议将权重设置为常数（如1或0）或基于某种固定的“常识”来设置，原因有以下几点：\n",
    "\n",
    "1. **数据不平衡**：在实际应用中，数据集通常是不平衡的，即某些类别的样本数量可能远多于其他类别。如果简单地使用常识来设置权重，可能会导致模型偏向于数量较多的类别，从而忽略或错误地分类数量较少的类别。\n",
    "2. **模型泛化能力**：机器学习模型的目标是从训练数据中学习到一般性的规律，从而能够泛化到未见过的数据上。如果权重设置过于简单或固定，模型可能无法充分学习到数据的复杂性，导致泛化能力下降。\n",
    "3. **优化难度**：在模型训练过程中，权重通常是通过优化算法（如梯度下降）来自动调整的。如果初始权重设置不合理，可能会导致优化过程变得困难或陷入局部最优解。\n",
    "4. **可解释性**：虽然基于常识设置权重可能使得模型更易于解释，但这种做法往往忽略了数据的复杂性。在很多情况下，数据的真实分布和模式可能比基于常识的假设更为复杂。\n",
    "\n",
    "因此，为了获得更好的训练效果和泛化能力，通常建议让模型自动学习权重。这可以通过使用适当的优化算法和损失函数来实现，例如使用交叉熵损失函数来训练分类模型，并使用梯度下降等优化算法来更新权重。同时，还可以通过一些技巧来平衡不同类别的样本，例如使用过采样或欠采样方法来处理不平衡数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93969c89-4627-4b6a-bc0c-9c5ed6705da3",
   "metadata": {},
   "source": [
    "对某些块应用不同的初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dca6bcbc-8987-41ab-b097-52e55514fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ca2b1ef-196e-4af3-8785-3e5bc234e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae83e01-d8f6-4a8b-8c4e-cf993ec41c2e",
   "metadata": {},
   "source": [
    "这段代码定义了一个名为 `xavier` 的函数，该函数用于初始化 PyTorch 神经网络中的线性层（全连接层）的权重。这个函数使用了 Xavier（或Glorot）均匀初始化方法，这是一种常用的权重初始化策略。下面是对代码的详细解释：\n",
    "\n",
    "1. `def xavier(m):`：定义了一个名为 `xavier` 的函数，该函数接受一个参数 `m`，通常代表神经网络中的一个模块（比如一个线性层）。\n",
    "2. `if type(m) == nn.Linear:`：这是一个条件语句，用于检查传入的模块 `m` 是否是线性层（`nn.Linear`）。只有当 `m` 是线性层时，接下来的初始化代码才会执行。\n",
    "3. `nn.init.xavier_uniform_(m.weight)`：这一行是初始化代码的核心。`nn.init.xavier_uniform_` 是 PyTorch 中的一个函数，用于对张量进行 Xavier 均匀初始化。这里的下划线 `_` 表示这个函数是原地操作（in-place operation），即它会直接修改传入的张量，而不是返回一个新的张量。\n",
    "\n",
    "\n",
    "\t* `xavier_uniform_` 函数接受一个张量作为参数，并将其初始化为从均匀分布中抽取的值。这个均匀分布的区间是 `[-a, a]`，其中 `a` 是根据张量的形状计算出来的一个常数，目的是使初始化后的权重具有合适的尺度。\n",
    "\t* Xavier 均匀初始化是一种旨在改善神经网络训练效果的权重初始化策略。它的基本思想是使每一层神经元的输入和输出的方差尽可能相等，从而避免在训练过程中出现梯度消失或梯度爆炸的问题。\n",
    "\n",
    "总体来说，这段代码定义了一个函数，用于将神经网络中的线性层的权重初始化为 Xavier 均匀分布的值。这是一种常用的权重初始化方法，有助于改善神经网络的训练稳定性和性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da6bec29-895b-4132-99d0-e8d0a52c0db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4, out_features=8, bias=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].apply(xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07fcc2bd-f2ad-4050-b2df-572be2eb7d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=1, bias=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].apply(init_42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9177adb5-f17a-4a41-b92e-2102d9fff29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6285, -0.3778, -0.5230, -0.3246])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee9631-ff17-41c1-967e-5e61172801da",
   "metadata": {},
   "source": [
    "自定义初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae617692-df54-451e-81c2-00e4a0ad43ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\n",
    "            \"init\",\n",
    "            *[(name, param.shape) for name, param in m.named_parameters()][0]\n",
    "        )\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fedfd86-13aa-421e-ba6c-0a4e6544d620",
   "metadata": {},
   "source": [
    "这段代码定义了一个名为 `my_init` 的函数，该函数用于初始化 PyTorch 神经网络中的模块，特别是线性层 (`nn.Linear`)。这个函数使用了自定义的权重初始化方法，并且打印了初始化过程中的一些信息。下面是对代码的详细解释：\n",
    "\n",
    "1. `def my_init(m):`：定义了一个名为 `my_init` 的函数，该函数接受一个参数 `m`，通常代表神经网络中的一个模块。\n",
    "\n",
    "2. `if type(m) == nn.Linear:`：这是一个条件语句，用于检查传入的模块 `m` 是否是线性层（`nn.Linear`）。只有当 `m` 是线性层时，接下来的初始化代码才会执行。\n",
    "\n",
    "3. `print(\"init\", *[(name, param.shape) for name, param in m.named_parameters()][0])`：这行代码打印一条消息，表明正在对某个模块进行初始化，并显示该模块的第一个参数的名称和形状。`m.named_parameters()` 是一个生成器，它返回模块中所有参数的名称和值。列表推导式 `[(name, param.shape) for name, param in m.named_parameters()]` 用于提取所有参数的名称和形状，并创建一个列表。由于我们知道线性层通常只有两个参数（`weight` 和 `bias`），所以列表推导式的结果是一个包含两个元组的列表。通过索引 `[0]`，我们获取第一个元组（即权重的名称和形状），并使用 `*` 解包操作符将其解包为单独的参数，以便 `print` 函数可以打印它们。\n",
    "\n",
    "4. `nn.init.uniform_(m.weight, -10, 10)`：这行代码使用均匀分布初始化线性层的权重。权重将被设置为在 `-10` 和 `10` 之间的随机值。下划线 `_` 表示这是一个原地操作，它会直接修改 `m.weight` 的值。\n",
    "\n",
    "5. `m.weight.data *= m.weight.data.abs() >= 5`：这行代码是一个逐元素的操作，用于进一步修改权重的值。它首先计算 `m.weight.data.abs() >= 5`，这会返回一个与权重形状相同的布尔张量，其中每个元素表示对应权重的绝对值是否大于或等于 5。然后，这个布尔张量被用作掩码，与原始权重进行逐元素的乘法操作。这意味着，如果权重的绝对值小于 5，它的值将被设置为 0；如果权重的绝对值大于或等于 5，它的值将保持不变。这种操作可以看作是一种硬阈值函数，用于将权重设置为 0 或保持其原始值（如果它足够大）。\n",
    "\n",
    "综上所述，`my_init` 函数是一个自定义的初始化函数，用于初始化 PyTorch 神经网络中的线性层。它使用均匀分布初始化权重，并通过一个硬阈值函数将绝对值较小的权重设置为 0。在初始化过程中，它还打印了权重的名称和形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "beaafe4c-2457-4576-b7bb-0afa88a45a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight torch.Size([8, 4])\n",
      "init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.apply(my_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82f7205b-2943-4d4f-8488-ee942d32048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5063,  0.0000, -0.0000,  9.2689],\n",
       "        [-5.0918, -6.0503, -0.0000,  6.7154]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7d8734f-cf65-4e23-8fa3-b7407ecaf40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-2.5063,  3.0000,  3.0000, 12.2689],\n",
      "        [-2.0918, -3.0503,  3.0000,  9.7154],\n",
      "        [ 3.0000, 11.4161, -4.5418, 12.3792],\n",
      "        [12.4252,  3.0000, -2.4871, -5.7381],\n",
      "        [11.8848,  3.0000,  3.0000,  3.0000],\n",
      "        [ 3.0000, -2.2451,  3.0000, 12.9304],\n",
      "        [-3.6574,  3.0000,  3.0000,  3.0000],\n",
      "        [ 9.5005, -2.3450,  3.0000,  3.0000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "net[0].weight.data[:] += 1\n",
    "print(net[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f6d0125-79dc-49c3-bafd-aec7ca2193f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[42.0000,  3.0000,  3.0000, 12.2689],\n",
      "        [-2.0918, -3.0503,  3.0000,  9.7154],\n",
      "        [ 3.0000, 11.4161, -4.5418, 12.3792],\n",
      "        [12.4252,  3.0000, -2.4871, -5.7381],\n",
      "        [11.8848,  3.0000,  3.0000,  3.0000],\n",
      "        [ 3.0000, -2.2451,  3.0000, 12.9304],\n",
      "        [-3.6574,  3.0000,  3.0000,  3.0000],\n",
      "        [ 9.5005, -2.3450,  3.0000,  3.0000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "net[0].weight.data[0,0] = 42\n",
    "print(net[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3988e3d-f884-472e-8370-de7a81851ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000,  3.0000,  3.0000, 12.2689])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e4013-6b7d-46f2-8534-c80ff80698f0",
   "metadata": {},
   "source": [
    "参数绑定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d1343a1-02b3-4090-a43f-0acb5b455bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared = nn.Linear(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb2efaea-3a3f-4de5-b509-0c591aeadad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(4, 8),\n",
    "                    nn.ReLU(),\n",
    "                    shared,\n",
    "                    nn.ReLU(),\n",
    "                    shared,\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(8,1)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b166723-de9b-4362-95cc-646af104f9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0252],\n",
       "        [-0.0444]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2e1b1f5-0c60-449d-b989-b92f47462385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2ffb354-84c2-4ca4-bf74-caabeb38c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net[2].weight.data[0, 0] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19ef967e-3140-40dd-a648-2463aefb2e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4f1e9-4e80-4d47-bed8-17038b718ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602f84a-a744-4337-a077-e1d56aae6954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
